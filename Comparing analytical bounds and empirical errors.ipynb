{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Comparing analytical bounds and empirical errors.ipynb","provenance":[],"collapsed_sections":["Wy_z-cnS9CAe","O_ubh9v2xTum"],"authorship_tag":"ABX9TyP6ol9N19uNpL5oSVZyg3Az"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"MjThG4Ra4RdH"},"source":["sample_size = 1000               #this is used to load the training_data\n","true_unknown_distribution = \"wiggly1\"             \n","is_agnostic = False\n","specific_hypothesis = 2\n","\n","epsilon = 0.05\n","hypothesis_class_cardinality = 10000\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJTqBz-v2qRX","executionInfo":{"status":"ok","timestamp":1634712899169,"user_tz":-330,"elapsed":26085,"user":{"displayName":"Kartik C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQR97Zx5OJULghBSrPRJbXoOA6FkugvnX9LOWnw=s64","userId":"00896101297542045226"}},"outputId":"559cb4ab-52aa-4c2e-a2cf-0228673432bb"},"source":["data_path = '/content/drive/My Drive/Simulations in Stat learning/data/'\n","distributions_path = '/content/drive/My Drive/Simulations in Stat learning/distributions/'\n","videos_path = '/content/drive/My Drive/Simulations in Stat learning/videos/'\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"eBqPHUbQ2P08"},"source":["import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wy_z-cnS9CAe"},"source":["# Helper functions"]},{"cell_type":"code","metadata":{"id":"PLKck9WL_zB4"},"source":["#Helper Functions\n","\n","def get_labels(x,y,distribution):\n","    if distribution == \"circle\":\n","        z = np.where(x**2 + y**2 + 2*0.9*x + 2*0.5*y - 0.2 > 0 , 1 , 0)  \n","        \n","    elif distribution == \"linear\":\n","        h_labeling = np.array([0.7,0.5])\n","        \n","        temp = np.r_[x,y]  #---for analytical and empirical comparison\n","        temp = temp.T\n","        z = np.where(np.matmul(temp,h_labeling) - 0> 0.0, 1, 0)\n","        \n","    elif distribution ==\"wiggly1\":\n","        z = np.where(3*y**3 +x**2 -0.2*y**2 +  0*x - 0.01   >0, 1, 0)\n","        \n","    elif distribution ==\"wiggly2\":\n","        z = np.where(30*x**10 + 2*y**10 -700*x**7 + 20*y**5 -1*x**2 + 0.02   >0, 0, 1)\n","        \n","    elif distribution == \"l1\":\n","        z1 = np.where(abs(x)+abs(y)>0.15,1,0)\n","        z2 = np.where(abs(x)+abs(y)>0.4,1,0)\n","\n","        z = np.logical_xor(z1,z2)\n","    \n","    else :\n","        filename = distributions_path + distribution + \".png\"\n","        im = plt.imread(filename)\n","        image = np.round(np.sum(im,2)/3)\n","\n","        x_ = np.floor((x + 0.4)*1000)\n","        y_ = np.floor((y + 0.4)*1000)\n","\n","        labels = []\n","        for i,j in zip(x_.astype(int),y_.astype(int)):\n","\n","            label = image[i,j]\n","            labels.append(label)\n","\n","        z = np.abs(1 - np.array(labels))\n","    \n","    \n","        \n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dn8qtufUqENs"},"source":["def errors_on_hypothesis_set(data,hypothesis):\n","    intermediate = np.matmul(data[:,:2], hypothesis)\n","    predictions = np.where(intermediate > 0.0, 1, 0)\n","    labels = data[:,2]\n","\n","    E_out = np.logical_xor(predictions.T,labels)\n","    true_errors = 1 - np.sum(E_out,axis=1)/E_out.shape[1]\n","    \n","    return true_errors,E_out[:8,:],predictions[:,:8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-nSoRg3V8_Ul"},"source":["def growth_function(n,vc_dim,vc_infinite):\n","  #this can be made tighter\n","  if vc_infinite:\n","    return np.power(2,n)\n","  else:\n","    return 4*(np.power(n,vc_dim)+1)\n","\n","def exponential_part(n,e):\n","  x = (-0.125)*e*e*n\n","  return np.exp(x)\n","  #return np.power(ep,x)\n","\n","#Guarentees of the sample of size n being e-representative if there are finite number of hypothesis or there are infinite number of hypothesis with \n","#a finite vc dimension\n","\n","def get_guarantee_infinite(n,e,vc_dim,vc_infinite):\n","  gf = growth_function(2*n,vc_dim,vc_infinite)\n","  ex = exponential_part(n,e)\n","  #what would be the prodict of these guys if vc dim is infinite\n","  return gf*ex,gf,ex \n","\n","def get_guarantee_finite(n, e , h):\n","    return 2.0 *h * np.exp(-2 * n * e * e)\n","\n","def get_plot_infinite(e,vc_dim,vc_infinite):\n","  guarantees = []\n","  growth_functions = []\n","  exponential_parts = []\n","  sample_sizes = []\n","\n","  if vc_infinite:\n","    start = 1\n","    end = 40\n","    diff = 1\n","  else:\n","    start = 30\n","    end =  10000\n","    diff = 1\n","\n","  for i in range(start,end,diff):\n","    sample_sizes.append(i)\n","\n","    delta,gf,ex = get_guarantee_infinite(i,e,vc_dim,vc_infinite)\n","    growth_functions.append(gf)\n","    exponential_parts.append(ex)\n","    guarantees.append(delta)\n","\n","  fig1,axs = plt.subplots(1,3)\n","  axs[0].plot(sample_sizes,growth_functions)\n","  axs[1].plot(sample_sizes,exponential_parts)\n","  axs[2].plot(sample_sizes,guarantees)\n","\n","def get_plot_finite(e,h):\n","  guarantees = []\n","  sample_sizes = []\n","  for i in range(30,10000,1):\n","    sample_sizes.append(i)\n","\n","    delta = get_guarantee_finite(i,e,h)\n","    guarantees.append(delta)\n","\n","  fig2,axs = plt.subplots(1,1)\n","  axs.plot(sample_sizes,guarantees)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O_ubh9v2xTum"},"source":["# Knobs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFmtsk3He9gE","executionInfo":{"status":"ok","timestamp":1640524834634,"user_tz":-330,"elapsed":15,"user":{"displayName":"Kartik C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQR97Zx5OJULghBSrPRJbXoOA6FkugvnX9LOWnw=s64","userId":"00896101297542045226"}},"outputId":"078f3efc-1939-4029-f24f-e7381d09f18d"},"source":["n = 300 #100,400,4000,10000,20000.\n","e = 0.1\n","vc_dim = 2\n","bound = get_guarantee_infinite(n,e,vc_dim,False)\n","print(bound)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(989699.310616115, 1440004, 0.6872892787909721)\n"]}]},{"cell_type":"code","metadata":{"id":"erJlL6no2Pod"},"source":["#Make a pattern out of these\n","n = sample_size\n","distribution = true_unknown_distribution\n","agnostic = is_agnostic  \n","\n","if agnostic == False:\n","  name = distribution\n","else:\n","  name = 'agnostic'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLwPQuVE2Phd"},"source":["data = np.load(data_path + \"data_\"+name+'_'+str(40000)+\".npy\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qh6iFpoW2PVJ"},"source":["#Constants relevant to the notebook\n","e = epsilon\n","vc_dim = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkSu8Cyd8tip"},"source":["num_hypothesis = hypothesis_class_cardinality\n","hypothesis = np.random.uniform(-1,1,[2,num_hypothesis])\n","\n","h8 = np.array([[0.5,0.5],\n","               [0.5,0],\n","               [0.5,-0.5],\n","               [-0.5,0.5],\n","               [-0.5,0],\n","               [-0.5,-0.5],\n","               [0,0.5],\n","               [0,-0.5]])\n","hypothesis[:,:8] = h8.T\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"452uaw9yqSvx"},"source":["true_errors,E_out,p_true = errors_on_hypothesis_set(data,hypothesis)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dFpu0yDw_MRT"},"source":["#Starting Analyisis"]},{"cell_type":"code","metadata":{"id":"lwKEY59z_MBr"},"source":["#Works well for n=1000,e=0.05,h = 10000 .\n","\n","\n","union_bound = get_guarantee_finite(n,e,num_hypothesis)\n","vc_bound = get_guarantee_infinite(n,e,vc_dim,vc_infinite=False) #Todo remove this redundancy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xZ60LiPR_L8S","executionInfo":{"status":"ok","timestamp":1628595661508,"user_tz":-330,"elapsed":19,"user":{"displayName":"Kartik C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQR97Zx5OJULghBSrPRJbXoOA6FkugvnX9LOWnw=s64","userId":"00896101297542045226"}},"outputId":"bda58b2c-b3be-4d88-f893-f78ee0bd36be"},"source":["union_bound"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["134.75893998170935"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4-p3Rlw_X95","executionInfo":{"status":"ok","timestamp":1628595661509,"user_tz":-330,"elapsed":15,"user":{"displayName":"Kartik C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQR97Zx5OJULghBSrPRJbXoOA6FkugvnX9LOWnw=s64","userId":"00896101297542045226"}},"outputId":"d2075d15-7455-4a53-a22d-a623d7cf64bb"},"source":["vc_bound"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11705852.989608785, 16000004, 0.7316156289466418)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"UrHd42EY1wnS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628595810910,"user_tz":-330,"elapsed":141422,"user":{"displayName":"Kartik C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMQR97Zx5OJULghBSrPRJbXoOA6FkugvnX9LOWnw=s64","userId":"00896101297542045226"}},"outputId":"9e6da8cb-a689-4250-e490-48579899d24a"},"source":["\n","\n","\n","e_representetive = 0\n","trials = 1000\n","for i in range(trials):\n","  #Make this efficient\n","  interpolated_points = np.random.uniform(-0.4,0.4,[1,n,2])\n","  interpolation_intermediate = np.matmul(interpolated_points,hypothesis)\n","  interpolation_predictions = np.where(interpolation_intermediate > 0.0, 1, 0) # I can bias term here\n"," \n","\n","  interpolation_labels = get_labels(interpolated_points[:,:,0],interpolated_points[:,:,1],distribution).reshape(1,n,1)\n","  #print(interpolation_predictions.shape)\n","  #print(interpolation_labels.shape)\n","  interpolation_in_error = 1 - np.sum(np.logical_xor(interpolation_predictions, interpolation_labels),axis=1)/interpolated_points.shape[1]\n","  interpolation_diff = np.abs(interpolation_in_error - true_errors)\n","\n","\n","  x = np.where(interpolation_diff>0.05)\n","  if x[0].size == 0:\n","    e_representetive+=1\n","\n","print(1 - (e_representetive/trials))\n","\n","# For circle decision boundry. Linear gives similar results? **OVERLAPS**\n","\n","#According to empirical tests,probability of 1000 point sample not being e-representative:(**This depends on the distribution!!??**)\n","#**0.012**,0.008 , 0.019 , 0.01\n","\n","#According to hoeffdings bound,probabilitiy of 1000 point sample not being e-representative is less than or equal to(**This is distribution agnostic**):\n","#134\n","#****\n","# For skull decision boundry\n","\n","#According to empirical tests,probability of 1000 point sample not being e-representative:(**This depends on the distribution!!??**)  **0.049**,0.033,0.039,0.0385,0.032\n","\n","#According to hoeffdings bound,probabilitiy of 1000 point sample not being e-representative is less than or equal to(**This is distribution agnostic**):\n","#**134**\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.027000000000000024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RtYoF-Rw2Okt"},"source":[""],"execution_count":null,"outputs":[]}]}